import streamlit as st
import openai
import os
import json

# Page configuration
st.set_page_config(layout="wide")

# --- Secrets & API Key Configuration ---
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OpenAI API key not found. Set it in .streamlit/secrets.toml or as environment variable OPENAI_API_KEY.")
    st.stop()
openai.api_key = api_key
client = openai.OpenAI()

# --- Helper Functions ---

def generate_questions(context: str) -> list[str]:
    prompt = (
        "ë‹¤ìŒ ì´ì•¼ê¸°ë¥¼ ì´ì–´ì“°ê¸° ìœ„í•´ ì ì ˆí•œ ì§ˆë¬¸ì„ 3ê°€ì§€ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n"
        "ì´ˆë“±í•™ìƒë“¤ì´ ì´ì•¼ê¸°ë¥¼ ì´ì–´ì“°ëŠ” ì§ˆë¬¸ì´ë‹ˆê¹Œ ë’· ì´ì•¼ê¸°ë¥¼ ê³„ì† ì´ì–´ë‚˜ê°ˆ ìˆ˜ ìˆë„ë¡ ìœ ë„í• ë§Œí•œ ì§ˆë¬¸ë“¤ì„ ì•„ë˜ì˜ ì§ˆë¬¸ íƒ€ì…ë“¤ì„ ì ì ˆí•˜ê²Œ ì„ì–´ì„œ 3ê°€ì§€ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”.\n"
        "ì§ˆë¬¸ íƒ€ì…ì˜ ì˜ˆì‹œ\n"
        "1. ë§Œì•½~ë¼ë©´ ì–´ë–»ê²Œ ë ê¹Œ? (ê°€ì •í˜• ì§ˆë¬¸) ex) ë§Œì•½ ë„ê¹¨ë¹„ ë°©ë§ì´ê°€ ë§í•˜ëŠ” ë¬¼ê±´ì´ë¼ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”?, ...\n"
        "2. ë¬´ìŠ¨ ì¼ì´ ìƒê²¼ì„ê¹Œ? ì´ì–´ê°€ê¸° ì§ˆë¬¸...\n"
        "3. ì¸ë¬¼ì˜ ë§ˆìŒì´ë‚˜ ì„ íƒì„ ë¬»ëŠ” ì§ˆë¬¸...\n"
        f"í˜„ì¬ ì´ì•¼ê¸°:\n{context}\n"
        "ì„¸ ê°€ì§€ ì§ˆë¬¸ì„ ê° ì¤„ì— í•˜ë‚˜ì”© ì‘ì„±í•˜ì„¸ìš”."
    )
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.9,
    )
    text = response.choices[0].message.content
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return lines[:3]


def generate_feedback(raw_text: str, context: str) -> dict:
    prompt = (
        "ë‹¤ìŒì€ ì´ì•¼ê¸° ë§¥ë½ê³¼ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.\n"
        f"ë§¥ë½:\n{context}\n"
        f"ì‚¬ìš©ì ì‘ì„±:\n{raw_text}\n\n"
        "ì´ í…ìŠ¤íŠ¸ì˜ *í‹€ë¦° ë¶€ë¶„*(errors)ê³¼ *ê³ ì¹  ë°©ë²•*(suggestions), "
        "ê·¸ë¦¬ê³  *ê°œì„ ëœ ë²„ì „*(improved) ì„¸ ê°€ì§€ë¥¼ ë°˜ë“œì‹œ JSON ê°ì²´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.\n"
        "ì˜ˆì‹œ í˜•ì‹:\n{\n  \"errors\": [...], \"suggestions\": [...], \"improved\": \"...\"\n}"
    )
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.9,
    )
    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        return {"errors": ["í”¼ë“œë°± ìƒì„± ì¤‘ íŒŒì‹± ì˜¤ë¥˜"], "suggestions": [], "improved": content}

# --- State Transition Helpers ---

def handle_start(summary: str):
    st.session_state.summary = summary
    st.session_state.current_segment = summary
    # ì§ˆë¬¸ ìƒì„± í›„, ê° ì§ˆë¬¸ì— ëŒ€í•œ ì…ë ¥ê³¼ í”¼ë“œë°± ì¹´ìš´íŠ¸ë¥¼ ì´ˆê¸°í™”
    st.session_state.questions = generate_questions(summary)
    n = len(st.session_state.questions)
    st.session_state.raw_inputs = [""] * n
    st.session_state.feedback_counts = [0] * n
    st.session_state.stage = "choose_q"


def choose_question(idx: int):
    st.session_state.selected_q_idx = idx
    st.session_state.stage = "write"


def submit_raw_input(text: str):
    idx = st.session_state.selected_q_idx
    st.session_state.raw_inputs[idx] = text
    st.session_state.stage = "review"


def on_feedback_decision(is_done: bool):
    idx = st.session_state.selected_q_idx
    if is_done or st.session_state.feedback_counts[idx] >= 2:
        st.session_state.current_segment += "\n" + st.session_state.raw_inputs[idx]
        st.session_state.stage = "decide_continue"
    else:
        st.session_state.feedback_counts[idx] += 1
        st.session_state.stage = "write"


def decide_continue(continue_story: bool):
    if continue_story:
        # ë‹¤ìŒ ì§ˆë¬¸ë“¤ ì¬ìƒì„±
        st.session_state.questions = generate_questions(st.session_state.current_segment)
        n = len(st.session_state.questions)
        st.session_state.raw_inputs = [""] * n
        st.session_state.feedback_counts = [0] * n
        st.session_state.stage = "choose_q"
    else:
        st.session_state.stage = "done"

# --- Initialize Session State ---
if 'stage' not in st.session_state:
    st.session_state.stage = "init"

# --- UI Flow ---
if st.session_state.stage == "init":
    st.title("ğŸ–‹ï¸ Interactive Story Builder with File Upload")
    st.write("ì‹œì‘í•  ì´ì•¼ê¸° ìš”ì•½ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¬¸ì„œ íŒŒì¼(.txt/.md)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    col1, col2 = st.columns(2)
    summary_input = ""
    with col1:
        summary_input = st.text_area("ì´ì•¼ê¸° ìš”ì•½ ì…ë ¥", height=200)
    with col2:
        uploaded_file = st.file_uploader("ë¬¸ì„œ ì—…ë¡œë“œ (.txt, .md)", type=["txt", "md"])
        if uploaded_file:
            try:
                summary_input = uploaded_file.read().decode('utf-8')
                st.success("íŒŒì¼ì—ì„œ ìš”ì•½ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            except Exception:
                st.error("íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    def _on_start():
        if summary_input.strip():
            with st.spinner("ì§ˆë¬¸ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”â€¦"):
                handle_start(summary_input.strip())
    st.button("ì‹œì‘í•˜ê¸°", on_click=_on_start)

elif st.session_state.stage == "choose_q":
    st.subheader("ë‹¤ìŒ ì „ê°œë¥¼ ì´ì–´ê°ˆ ì§ˆë¬¸ì„ ê³¨ë¼ì£¼ì„¸ìš”:")
    for i, q in enumerate(st.session_state.questions):
        st.button(q, key=f"q{i}", on_click=lambda i=i: choose_question(i))

elif st.session_state.stage == "write":
    idx = st.session_state.selected_q_idx
    st.subheader(f"ì§ˆë¬¸: {st.session_state.questions[idx]}")
    user_text = st.text_area("ë‹µë³€ ì…ë ¥", value=st.session_state.raw_inputs[idx], height=200)
    st.button("ì œì¶œ", on_click=lambda text=user_text: submit_raw_input(text))

elif st.session_state.stage == "review":
    idx = st.session_state.selected_q_idx
    st.subheader("ğŸ” í”¼ë“œë°± ì˜ì—­")
    with st.spinner("í”¼ë“œë°± ìƒì„± ì¤‘..."):
        fb = generate_feedback(st.session_state.raw_inputs[idx], st.session_state.current_segment)
    st.session_state.fb = fb

    st.markdown("**âŒ í‹€ë¦° ë¶€ë¶„ (errors):**")
    for err in fb.get("errors", []):
        st.markdown(f"- {err}")

    st.markdown("**ğŸ’¡ ê³ ì¹  ë°©ë²• (suggestions):**")
    for sug in fb.get("suggestions", []):
        st.markdown(f"- {sug}")

    st.markdown("**âœ¨ ê°œì„ ëœ ì˜ˆì‹œ:**")
    st.text_area("", value=fb.get("improved", ""), height=200)

    def apply_improved():
        st.session_state.raw_inputs[idx] = st.session_state.fb.get("improved", "")
        on_feedback_decision(True)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.button("ìˆ˜ì •í•˜ê¸°", on_click=lambda: on_feedback_decision(False))
    with col2:
        st.button("ì™„ë£Œí•˜ê¸°", on_click=lambda: on_feedback_decision(True))
    with col3:
        st.button("ê°œì„  ë²„ì „ ì ìš©í•˜ê¸°", on_click=apply_improved)

elif st.session_state.stage == "decide_continue":
    st.subheader("ğŸ“– ì§€ê¸ˆê¹Œì§€ ì´ì–´ì§„ ì´ì•¼ê¸°")
    st.text_area("", value=st.session_state.current_segment, height=300)
    st.subheader("ì´ì•¼ê¸°ë¥¼ ê³„ì† ì´ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ?")
    col1, col2 = st.columns(2)
    with col1:
        st.button("ê³„ì† ì´ì–´ì“°ê¸°", on_click=lambda: decide_continue(True))
    with col2:
        st.button("ì´ì•¼ê¸° ì™„ì„±í•˜ê¸°", on_click=lambda: decide_continue(False))

elif st.session_state.stage == "done":
    st.subheader("âœ… ìµœì¢… ì™„ì„±ëœ ì´ì•¼ê¸°")
    st.text_area("Story", value=st.session_state.current_segment, height=400)
    st.success("ì´ì•¼ê¸°ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")